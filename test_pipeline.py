#!/usr/bin/env python
"""Test script for the complete document processing pipeline."""

import sys
sys.path.append('/workspaces/pdfhikaku')

from pdfhikaku import DocumentProcessor, DocumentComparator

def test_document_pipeline():
    """Test the complete document processing and comparison pipeline."""

    print("ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)

    # Create sample PDF pages (simulating extracted text)
    sample_pages_a = [
        {
            "page": 1,
            "text": """
            1ç«  æ¦‚è¦
            1-1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
            ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯...
            """,
            "blocks": [],
            "headings": [
                {"text": "1ç«  æ¦‚è¦", "level": 1, "font_size": 18},
                {"text": "1-1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦", "level": 2, "font_size": 14}
            ]
        },
        {
            "page": 2,
            "text": """
            2ç«  ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ
            2-1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
            ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹æˆã¯...
            """,
            "blocks": [],
            "headings": [
                {"text": "2ç«  ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ", "level": 1, "font_size": 18},
                {"text": "2-1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "level": 2, "font_size": 14}
            ]
        }
    ]

    sample_pages_b = [
        {
            "page": 1,
            "text": """
            1ç«  æ¦‚è¦
            1-1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
            ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦...
            """,
            "blocks": [],
            "headings": [
                {"text": "1ç«  æ¦‚è¦", "level": 1, "font_size": 18},
                {"text": "1-1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦", "level": 2, "font_size": 14}
            ]
        },
        {
            "page": 2,
            "text": """
            2ç«  ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ
            2-1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
            ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã¯...
            """,
            "blocks": [],
            "headings": [
                {"text": "2ç«  ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ", "level": 1, "font_size": 18},
                {"text": "2-1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "level": 2, "font_size": 14}
            ]
        }
    ]

    # Initialize processor and comparator
    processor = DocumentProcessor(use_ocr=False)
    comparator = DocumentComparator(similarity_threshold=0.6, granularity="sentence")

    # Simulate document processing (normally would extract from PDF)
    print("ğŸ“„ Step 1-4: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ä¸­...")

    # Manually create document structures for testing
    doc_a = simulate_document_processing(processor, sample_pages_a, "Document A")
    doc_b = simulate_document_processing(processor, sample_pages_b, "Document B")

    # Step 5-6: Compare documents
    print("ğŸ” Step 5-6: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¯”è¼ƒä¸­...")
    comparison = comparator.compare_documents(doc_a, doc_b)

    # Display results
    print("\nğŸ“Š æ¯”è¼ƒçµæœ:")
    print(f"  - å…¨ä½“ä¸€è‡´ç‡: {comparison['overall_similarity']:.2f}%")
    print(f"  - ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œæ•°: {len(comparison['section_mappings'])}")
    print(f"  - æ¯”è¼ƒçµæœæ•°: {len(comparison['comparison_results'])}")

    print("\nğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œ:")
    for mapping in comparison['section_mappings']:
        print(f"  - '{mapping['A_title']}' â†” '{mapping['B_title']}' (é¡ä¼¼åº¦: {mapping['score']:.2f})")

    print("\nğŸ“ˆ å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é¡ä¼¼åº¦:")
    for result in comparison['comparison_results']:
        print(f"  - {result['mapping']['A_title']}: {result['similarity']:.2f}%")

    print("\nâœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†!")
    return True

def simulate_document_processing(processor, pages, doc_name):
    """Simulate document processing for testing."""
    print(f"  Processing {doc_name}...")

    # Step 2: Detect headings
    headings = processor.heading_detector.detect_headings_from_pages(pages)
    print(f"    - æ¤œå‡ºã•ã‚ŒãŸè¦‹å‡ºã—: {len(headings)}å€‹")

    # Step 3: Generate sections
    sections_by_chapter = processor.section_generator.generate_sections(pages, headings)
    print(f"    - ç”Ÿæˆã•ã‚ŒãŸç« : {len(sections_by_chapter)}ç« ")

    # Step 4: Generate TOC
    toc = processor.toc_generator.generate_toc(sections_by_chapter)
    print(f"    - ç›®æ¬¡ã‚¨ãƒ³ãƒˆãƒª: {len(toc)}å€‹")

    return {
        'pages': pages,
        'headings': headings,
        'sections_by_chapter': sections_by_chapter,
        'toc': toc
    }

if __name__ == "__main__":
    try:
        success = test_document_pipeline()
        if success:
            print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã«åˆæ ¼ã—ã¾ã—ãŸï¼")
        else:
            print("\nâŒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()