#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Test script to verify enhanced RAG functionality with structured JSON responses
"""

import os
import json
from utils.pinecone_io import PineconeManager
import openai


class EnhancedRAGTester:
    def __init__(self):
        self.client = openai.OpenAI(api_key=os.environ["OPENAI_API_KEY"])
        self.embedding_model = "text-embedding-3-small"
        self.chat_model = "gpt-3.5-turbo"
        self.pinecone_manager = PineconeManager()
        
        self.system_prompt = """ã‚ãªãŸã¯ä¼æ¥­å†…è¦å®šã«é–¢ã™ã‚‹QAã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæ–‡è„ˆï¼ˆretrieved_contextï¼‰ã®æƒ…å ±ã®ã¿ã‚’æ ¹æ‹ ã¨ã—ã¦ã€è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã—ã¦ã€**å¿…ãšJSONã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›æ§‹é€ ã€‘

{
  "answer": "è³ªå•ã«å¯¾ã™ã‚‹ç°¡æ½”ãªçµè«–ï¼ˆ1ï½3æ–‡ï¼‰",
  "explanation": "èƒŒæ™¯ã‚„æ³¨æ„ç‚¹ã‚’å«ã‚€è§£èª¬ï¼ˆ5ï½8æ–‡ã€å°‚é–€ç”¨èªã¯ã‚„ã•ã—ãï¼‰",
  "highlights": [
    {
      "source_id": "company_policies",
      "chunk_index": 12,
      "span": [128, 215],
      "quote": "å¾“æ¥­å“¡ã¯...ã‚ã‚‰ã‹ã˜ã‚ç”³è«‹ãŒå¿…è¦ã§ã™ã€‚"
    }
  ],
  "sources": [
    {
      "source_id": "company_policies",
      "chunk_index": 12,
      "confidence": "High"
    }
  ]
}

ã€ãƒ«ãƒ¼ãƒ«ã€‘

1. answer ã¯äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
2. explanation ã¯è¦ç‚¹ãƒ»èƒŒæ™¯ãƒ»æ³¨æ„ç‚¹ã‚’å«ã‚ã€èª­ã¿æ‰‹ãŒç†è§£ã—ã‚„ã™ã„æ§‹æˆã«ã—ã¦ãã ã•ã„ï¼ˆç®‡æ¡æ›¸ãå¯ï¼‰ã€‚
3. highlights ã¯åŸæ–‡ã®é‡è¦ãªéƒ¨åˆ†ã‚’ãã®ã¾ã¾çŸ­ãå¼•ç”¨ã—ã€ãƒãƒ£ãƒ³ã‚¯å†…ã®æ–‡å­—ç¯„å›² [start, end] ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆæœ€å¤§5ä»¶ï¼‰ã€‚
4. sources ã¯å›ç­”ã«ä½¿ã£ãŸãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã¾ã¨ã‚ã€confidence ã‚’ "High" / "Med" / "Low" ã®ã„ãšã‚Œã‹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
5. ä¸æ˜ãªå ´åˆã¯ "ä¸æ˜ã§ã™" ã¨ç­”ãˆã€è¿½åŠ ã§å¿…è¦ãªæƒ…å ±ã‚’1ã€œ2ç‚¹æç¤ºã—ã¦ãã ã•ã„ã€‚
6. æ¨æ¸¬ã™ã‚‹å ´åˆã¯ "æ¨æ¸¬: ..." ã¨æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚
7. JSON ä»¥å¤–ã®æ–‡å­—åˆ—ï¼ˆèª¬æ˜æ–‡ã‚„æ³¨é‡ˆï¼‰ã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    def create_query_embedding(self, query: str):
        """ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=query
        )
        return response.data[0].embedding
    
    def search_relevant_chunks(self, query: str, top_k: int = 3):
        """é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
        query_vector = self.create_query_embedding(query)
        return self.pinecone_manager.search_similar(query_vector, top_k=top_k)
    
    def generate_enhanced_response(self, query: str, context_chunks):
        """æ§‹é€ åŒ–ã•ã‚ŒãŸJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        # retrieved_context ã‚’æ§‹ç¯‰
        retrieved_context = []
        for i, chunk in enumerate(context_chunks):
            retrieved_context.append({
                "source_id": "company_policies",
                "chunk_index": chunk["metadata"]["chunk_index"],
                "text": chunk["text"],
                "char_start": chunk["metadata"]["char_start"],
                "char_end": chunk["metadata"]["char_end"]
            })
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        user_message = {
            "question": query,
            "retrieved_context": retrieved_context
        }
        
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": json.dumps(user_message, ensure_ascii=False, indent=2)}
        ]
        
        response = self.client.chat.completions.create(
            model=self.chat_model,
            messages=messages,
            temperature=0.1,
            max_tokens=800
        )
        
        # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            response_text = response.choices[0].message.content.strip()
            # JSONãƒãƒ¼ã‚«ãƒ¼ãŒã‚ã‚‹å ´åˆã¯é™¤å»
            if response_text.startswith('```json'):
                response_text = response_text[7:-3].strip()
            elif response_text.startswith('```'):
                response_text = response_text[3:-3].strip()
            
            parsed_response = json.loads(response_text)
            return parsed_response
        except json.JSONDecodeError as e:
            return {
                "answer": f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "explanation": f"åŸæ–‡: {response_text[:200]}...",
                "highlights": [],
                "sources": []
            }


def test_enhanced_rag():
    """æ‹¡å¼µRAGã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸš€ æ‹¡å¼µRAGã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    tester = EnhancedRAGTester()
    
    test_queries = [
        "ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ ã®ã‚³ã‚¢ã‚¿ã‚¤ãƒ ã¯ä½•æ™‚ã§ã™ã‹ï¼Ÿ",
        "æ™‚é–“å¤–å‹¤å‹™ã®ä¸Šé™æ™‚é–“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "æœ‰çµ¦ä¼‘æš‡ã®ç”³è«‹ã¯ã„ã¤ã¾ã§ã«è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}. è³ªå•: {query}")
        print("-" * 30)
        
        try:
            # é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢
            context_chunks = tester.search_relevant_chunks(query, top_k=3)
            print(f"æ¤œç´¢çµæœ: {len(context_chunks)}ä»¶")
            
            # æ‹¡å¼µå¿œç­”ã‚’ç”Ÿæˆ
            response = tester.generate_enhanced_response(query, context_chunks)
            
            # çµæœã‚’è¡¨ç¤º
            print(f"\nğŸ“ å›ç­”: {response.get('answer', 'N/A')}")
            print(f"\nğŸ’¡ è§£èª¬: {response.get('explanation', 'N/A')}")
            
            # ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
            highlights = response.get('highlights', [])
            if highlights:
                print(f"\nğŸ” å¼•ç”¨ãƒã‚¤ãƒ©ã‚¤ãƒˆ ({len(highlights)}ä»¶):")
                for j, highlight in enumerate(highlights, 1):
                    print(f"  {j}. ãƒãƒ£ãƒ³ã‚¯ {highlight.get('chunk_index', 'N/A')}")
                    print(f"     å¼•ç”¨: \"{highlight.get('quote', 'N/A')}\"")
                    print(f"     ä½ç½®: {highlight.get('span', 'N/A')}")
            
            # å‡ºå…¸è¡¨ç¤º
            sources = response.get('sources', [])
            if sources:
                print(f"\nğŸ“š å‡ºå…¸ ({len(sources)}ä»¶):")
                for source in sources:
                    confidence_emoji = {
                        "High": "ğŸŸ¢", 
                        "Med": "ğŸŸ¡", 
                        "Low": "ğŸ”´"
                    }.get(source.get('confidence', 'Med'), "âšª")
                    
                    print(f"  {confidence_emoji} ãƒãƒ£ãƒ³ã‚¯ {source.get('chunk_index', 'N/A')} - ä¿¡é ¼åº¦: {source.get('confidence', 'Med')}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("\n" + "=" * 50)


if __name__ == "__main__":
    test_enhanced_rag()